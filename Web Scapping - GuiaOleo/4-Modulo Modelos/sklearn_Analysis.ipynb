{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resto</th>\n",
       "      <th>fecha</th>\n",
       "      <th>review</th>\n",
       "      <th>comida</th>\n",
       "      <th>servicio</th>\n",
       "      <th>ambiente</th>\n",
       "      <th>tokened</th>\n",
       "      <th>normal</th>\n",
       "      <th>nonstop</th>\n",
       "      <th>nopoint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-amigos-del-mar-608</td>\n",
       "      <td>12/07/2015</td>\n",
       "      <td>el mejor lugar de la Argentina para comer comi...</td>\n",
       "      <td>Excelente</td>\n",
       "      <td>Excelente</td>\n",
       "      <td>Excelente</td>\n",
       "      <td>['el', 'mejor', 'lugar', 'de', 'la', 'Argentin...</td>\n",
       "      <td>['el', 'mejor', 'lugar', 'de', 'la', 'argentin...</td>\n",
       "      <td>['mejor', 'lugar', 'argentina', 'comer', 'comi...</td>\n",
       "      <td>['mejor', 'lugar', 'argentina', 'comer', 'comi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-amigos-del-mar-608</td>\n",
       "      <td>22/06/2015</td>\n",
       "      <td>El Curry Udon excelente, hacía mucho que no co...</td>\n",
       "      <td>Muy bueno</td>\n",
       "      <td>Excelente</td>\n",
       "      <td>Excelente</td>\n",
       "      <td>['El', 'Curry', 'Udon', 'excelente', ',', 'hac...</td>\n",
       "      <td>['el', 'curry', 'udon', 'excelente', ',', 'hac...</td>\n",
       "      <td>['curry', 'udon', 'excelente', ',', 'hacía', '...</td>\n",
       "      <td>['curry', 'udon', 'excelente', 'hacía', 'comía...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-amigos-del-mar-608</td>\n",
       "      <td>06/01/2015</td>\n",
       "      <td>La relación calidad-precio fue mala (muy caro ...</td>\n",
       "      <td>Muy bueno</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Muy bueno</td>\n",
       "      <td>['La', 'relación', 'calidad-precio', 'fue', 'm...</td>\n",
       "      <td>['la', 'relación', 'calidad-precio', 'fue', 'm...</td>\n",
       "      <td>['relación', 'calidad-precio', 'mala', '(', 'c...</td>\n",
       "      <td>['relación', 'calidad-precio', 'mala', 'caro',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-amigos-del-mar-608</td>\n",
       "      <td>28/08/2013</td>\n",
       "      <td>Muy buena atención y calidez del lugar.</td>\n",
       "      <td>Excelente</td>\n",
       "      <td>Excelente</td>\n",
       "      <td>Excelente</td>\n",
       "      <td>['Muy', 'buena', 'atención', 'y', 'calidez', '...</td>\n",
       "      <td>['muy', 'buena', 'atención', 'y', 'calidez', '...</td>\n",
       "      <td>['buena', 'atención', 'calidez', 'lugar', '.']</td>\n",
       "      <td>['buena', 'atención', 'calidez', 'lugar']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-amigos-del-mar-608</td>\n",
       "      <td>25/01/2012</td>\n",
       "      <td>Excelente sushi. La atención es inmejorable. S...</td>\n",
       "      <td>Bueno</td>\n",
       "      <td>Excelente</td>\n",
       "      <td>Excelente</td>\n",
       "      <td>['Excelente', 'sushi', '.', 'La', 'atención', ...</td>\n",
       "      <td>['excelente', 'sushi', '.', 'la', 'atención', ...</td>\n",
       "      <td>['excelente', 'sushi', '.', 'atención', 'inmej...</td>\n",
       "      <td>['excelente', 'sushi', 'atención', 'inmejorabl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 resto       fecha  \\\n",
       "0  -amigos-del-mar-608  12/07/2015   \n",
       "1  -amigos-del-mar-608  22/06/2015   \n",
       "2  -amigos-del-mar-608  06/01/2015   \n",
       "3  -amigos-del-mar-608  28/08/2013   \n",
       "4  -amigos-del-mar-608  25/01/2012   \n",
       "\n",
       "                                              review     comida   servicio  \\\n",
       "0  el mejor lugar de la Argentina para comer comi...  Excelente  Excelente   \n",
       "1  El Curry Udon excelente, hacía mucho que no co...  Muy bueno  Excelente   \n",
       "2  La relación calidad-precio fue mala (muy caro ...  Muy bueno    Regular   \n",
       "3            Muy buena atención y calidez del lugar.  Excelente  Excelente   \n",
       "4  Excelente sushi. La atención es inmejorable. S...      Bueno  Excelente   \n",
       "\n",
       "    ambiente                                            tokened  \\\n",
       "0  Excelente  ['el', 'mejor', 'lugar', 'de', 'la', 'Argentin...   \n",
       "1  Excelente  ['El', 'Curry', 'Udon', 'excelente', ',', 'hac...   \n",
       "2  Muy bueno  ['La', 'relación', 'calidad-precio', 'fue', 'm...   \n",
       "3  Excelente  ['Muy', 'buena', 'atención', 'y', 'calidez', '...   \n",
       "4  Excelente  ['Excelente', 'sushi', '.', 'La', 'atención', ...   \n",
       "\n",
       "                                              normal  \\\n",
       "0  ['el', 'mejor', 'lugar', 'de', 'la', 'argentin...   \n",
       "1  ['el', 'curry', 'udon', 'excelente', ',', 'hac...   \n",
       "2  ['la', 'relación', 'calidad-precio', 'fue', 'm...   \n",
       "3  ['muy', 'buena', 'atención', 'y', 'calidez', '...   \n",
       "4  ['excelente', 'sushi', '.', 'la', 'atención', ...   \n",
       "\n",
       "                                             nonstop  \\\n",
       "0  ['mejor', 'lugar', 'argentina', 'comer', 'comi...   \n",
       "1  ['curry', 'udon', 'excelente', ',', 'hacía', '...   \n",
       "2  ['relación', 'calidad-precio', 'mala', '(', 'c...   \n",
       "3     ['buena', 'atención', 'calidez', 'lugar', '.']   \n",
       "4  ['excelente', 'sushi', '.', 'atención', 'inmej...   \n",
       "\n",
       "                                             nopoint  \n",
       "0  ['mejor', 'lugar', 'argentina', 'comer', 'comi...  \n",
       "1  ['curry', 'udon', 'excelente', 'hacía', 'comía...  \n",
       "2  ['relación', 'calidad-precio', 'mala', 'caro',...  \n",
       "3          ['buena', 'atención', 'calidez', 'lugar']  \n",
       "4  ['excelente', 'sushi', 'atención', 'inmejorabl...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('reviews_sep2_clean.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your conditions:\n",
    "conds = [(df['comida']=='Excelente')&(df['servicio']=='Excelente')&(df['ambiente']=='Excelente'), \n",
    "         (df['comida']=='Regular')&(df['servicio']=='Regular')&(df['ambiente']=='Regular')]\n",
    "\n",
    "# Set the values for each conditions\n",
    "choices = [1, 0]\n",
    "\n",
    "# Use np.select with a default of 3 (your \"else\" value)    \n",
    "df['Rating'] = np.select(conds, choices, default = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28286, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resto</th>\n",
       "      <th>fecha</th>\n",
       "      <th>review</th>\n",
       "      <th>comida</th>\n",
       "      <th>servicio</th>\n",
       "      <th>ambiente</th>\n",
       "      <th>tokened</th>\n",
       "      <th>normal</th>\n",
       "      <th>nonstop</th>\n",
       "      <th>nopoint</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-amigos-del-mar-608</td>\n",
       "      <td>12/07/2015</td>\n",
       "      <td>el mejor lugar de la Argentina para comer comi...</td>\n",
       "      <td>Excelente</td>\n",
       "      <td>Excelente</td>\n",
       "      <td>Excelente</td>\n",
       "      <td>['el', 'mejor', 'lugar', 'de', 'la', 'Argentin...</td>\n",
       "      <td>['el', 'mejor', 'lugar', 'de', 'la', 'argentin...</td>\n",
       "      <td>['mejor', 'lugar', 'argentina', 'comer', 'comi...</td>\n",
       "      <td>['mejor', 'lugar', 'argentina', 'comer', 'comi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-amigos-del-mar-608</td>\n",
       "      <td>22/06/2015</td>\n",
       "      <td>El Curry Udon excelente, hacía mucho que no co...</td>\n",
       "      <td>Muy bueno</td>\n",
       "      <td>Excelente</td>\n",
       "      <td>Excelente</td>\n",
       "      <td>['El', 'Curry', 'Udon', 'excelente', ',', 'hac...</td>\n",
       "      <td>['el', 'curry', 'udon', 'excelente', ',', 'hac...</td>\n",
       "      <td>['curry', 'udon', 'excelente', ',', 'hacía', '...</td>\n",
       "      <td>['curry', 'udon', 'excelente', 'hacía', 'comía...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-amigos-del-mar-608</td>\n",
       "      <td>06/01/2015</td>\n",
       "      <td>La relación calidad-precio fue mala (muy caro ...</td>\n",
       "      <td>Muy bueno</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Muy bueno</td>\n",
       "      <td>['La', 'relación', 'calidad-precio', 'fue', 'm...</td>\n",
       "      <td>['la', 'relación', 'calidad-precio', 'fue', 'm...</td>\n",
       "      <td>['relación', 'calidad-precio', 'mala', '(', 'c...</td>\n",
       "      <td>['relación', 'calidad-precio', 'mala', 'caro',...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-amigos-del-mar-608</td>\n",
       "      <td>28/08/2013</td>\n",
       "      <td>Muy buena atención y calidez del lugar.</td>\n",
       "      <td>Excelente</td>\n",
       "      <td>Excelente</td>\n",
       "      <td>Excelente</td>\n",
       "      <td>['Muy', 'buena', 'atención', 'y', 'calidez', '...</td>\n",
       "      <td>['muy', 'buena', 'atención', 'y', 'calidez', '...</td>\n",
       "      <td>['buena', 'atención', 'calidez', 'lugar', '.']</td>\n",
       "      <td>['buena', 'atención', 'calidez', 'lugar']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-amigos-del-mar-608</td>\n",
       "      <td>25/01/2012</td>\n",
       "      <td>Excelente sushi. La atención es inmejorable. S...</td>\n",
       "      <td>Bueno</td>\n",
       "      <td>Excelente</td>\n",
       "      <td>Excelente</td>\n",
       "      <td>['Excelente', 'sushi', '.', 'La', 'atención', ...</td>\n",
       "      <td>['excelente', 'sushi', '.', 'la', 'atención', ...</td>\n",
       "      <td>['excelente', 'sushi', '.', 'atención', 'inmej...</td>\n",
       "      <td>['excelente', 'sushi', 'atención', 'inmejorabl...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 resto       fecha  \\\n",
       "0  -amigos-del-mar-608  12/07/2015   \n",
       "1  -amigos-del-mar-608  22/06/2015   \n",
       "2  -amigos-del-mar-608  06/01/2015   \n",
       "3  -amigos-del-mar-608  28/08/2013   \n",
       "4  -amigos-del-mar-608  25/01/2012   \n",
       "\n",
       "                                              review     comida   servicio  \\\n",
       "0  el mejor lugar de la Argentina para comer comi...  Excelente  Excelente   \n",
       "1  El Curry Udon excelente, hacía mucho que no co...  Muy bueno  Excelente   \n",
       "2  La relación calidad-precio fue mala (muy caro ...  Muy bueno    Regular   \n",
       "3            Muy buena atención y calidez del lugar.  Excelente  Excelente   \n",
       "4  Excelente sushi. La atención es inmejorable. S...      Bueno  Excelente   \n",
       "\n",
       "    ambiente                                            tokened  \\\n",
       "0  Excelente  ['el', 'mejor', 'lugar', 'de', 'la', 'Argentin...   \n",
       "1  Excelente  ['El', 'Curry', 'Udon', 'excelente', ',', 'hac...   \n",
       "2  Muy bueno  ['La', 'relación', 'calidad-precio', 'fue', 'm...   \n",
       "3  Excelente  ['Muy', 'buena', 'atención', 'y', 'calidez', '...   \n",
       "4  Excelente  ['Excelente', 'sushi', '.', 'La', 'atención', ...   \n",
       "\n",
       "                                              normal  \\\n",
       "0  ['el', 'mejor', 'lugar', 'de', 'la', 'argentin...   \n",
       "1  ['el', 'curry', 'udon', 'excelente', ',', 'hac...   \n",
       "2  ['la', 'relación', 'calidad-precio', 'fue', 'm...   \n",
       "3  ['muy', 'buena', 'atención', 'y', 'calidez', '...   \n",
       "4  ['excelente', 'sushi', '.', 'la', 'atención', ...   \n",
       "\n",
       "                                             nonstop  \\\n",
       "0  ['mejor', 'lugar', 'argentina', 'comer', 'comi...   \n",
       "1  ['curry', 'udon', 'excelente', ',', 'hacía', '...   \n",
       "2  ['relación', 'calidad-precio', 'mala', '(', 'c...   \n",
       "3     ['buena', 'atención', 'calidez', 'lugar', '.']   \n",
       "4  ['excelente', 'sushi', '.', 'atención', 'inmej...   \n",
       "\n",
       "                                             nopoint  Rating  \n",
       "0  ['mejor', 'lugar', 'argentina', 'comer', 'comi...       1  \n",
       "1  ['curry', 'udon', 'excelente', 'hacía', 'comía...       3  \n",
       "2  ['relación', 'calidad-precio', 'mala', 'caro',...       3  \n",
       "3          ['buena', 'atención', 'calidez', 'lugar']       1  \n",
       "4  ['excelente', 'sushi', 'atención', 'inmejorabl...       3  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5745, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminamos los ratings iguales a 3 por ser neutrales\n",
    "df_rating = df[df['Rating'] != 3]\n",
    "df_rating.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6607484769364665"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vemos como estan balanceadas las clases\n",
    "df_rating['Rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data en sets de training y test \n",
    "X_train, X_test, y_train, y_test = train_test_split(df_rating['review'], \n",
    "                                                    df_rating['Rating'], \n",
    "                                                    random_state=0,\n",
    "                                                   stratify=df_rating['Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primera observación del X_train:\n",
      "\n",
      " De turismo en BsAs fuimos con mi flia a este restaurante. El mozo atrevido y maleducado al preguntar cuanto demoraria en servir lo pedido me contesto \"mas o menos cinco horas\". 45 minutos demoraron para servir una tortilla..y lo demas. Eramos 3. La comida malísima..recalentada. Fuimos con una tia de 86 años y nada de consideración ni por ella. De terror !.\n",
      "\n",
      "\n",
      "X_train shape:  (4308,)\n"
     ]
    }
   ],
   "source": [
    "print('Primera observación del X_train:\\n\\n', X_train.iloc[0])\n",
    "print('\\n\\nX_train shape: ', X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Fiteamos el CountVectorizer a los datos de entrenamiento\n",
    "vect = CountVectorizer().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.get_feature_names())\n",
    "type(vect.vocabulary_)\n",
    "len(vect.stop_words_ )\n",
    "#vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00', 'cabilú', 'desbordan', 'gastarse', 'materiales', 'predio', 'soupe']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# devuelve uno cada 2000. nada para el primer argumento, nada para el segundo, 2000 para el tercero\n",
    "# desde hasta step\n",
    "vect.get_feature_names()[::2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13524"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4308x13524 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 140410 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transformamos los documentos del training set a una matriz de documentos-términos:\n",
    "\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "X_train_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Entrenamos el modelo\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC sobre el set de testeo:  0.9186201178116741\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Hacemos las predicciones sobre el set de testeo:\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "\n",
    "print('AUC sobre el set de testeo: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefs menores:\n",
      "['mala' 'mal' 'peor' 'malo' 'cuarta' 'desastre' 'horrible' 'deja' 'desear'\n",
      " 'malisimo']\n",
      "\n",
      "Coefs mayores: \n",
      "['excelente' 'espectacular' 'exelente' 'exquisito' 'excelentes' 'super'\n",
      " 'falla' 'encanto' 'puede' 'exquisitos']\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos los nombres de las features como un array de numpy\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "# Ordenamos a los coeficientes del modelo\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "# Observamos a los 10 coeficientes más grandes y más chicos:\n",
    "print('Coefs menores:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Coefs mayores: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns;\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# mat = confusion_matrix(y_test, labels)\n",
    "# sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "#             xticklabels=['Clarin','Pagina'], yticklabels=['Clarin','Pagina'])\n",
    "# plt.xlabel('true label')\n",
    "# plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2810"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# en el anterior las palabras positivas y negativas las saca en función de la frecuencia pero sin darle ningun peso\n",
    "# acá asigna un peso en función de cuantas veces aparece con relación al corpus, pesa más las palabras menos frecuentes\n",
    "# y descarta las que son muy frecuentes con respecto al corpus porque no dicen nada\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Fiteamos el TfidfVectorizer al set de entrenamiento definiento un min_df_min=5\n",
    "vect = TfidfVectorizer(min_df=5).fit(X_train)\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.9232744994731297\n"
     ]
    }
   ],
   "source": [
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefs menores:\n",
      "['bieeeennn' 'baguette' 'baguetines' 'bibifes' 'alimento' 'brochete'\n",
      " 'bailaor' 'beruti' 'aspecto' 'calida']\n",
      "\n",
      "Coefs mayores: \n",
      "['aparecen' 'bem' 'absolutamente' 'ante' 'cerrados' 'caída' 'bandas'\n",
      " 'animadoras' 'caracúlico' 'cancha']\n"
     ]
    }
   ],
   "source": [
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "print('Coefs menores:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Coefs mayores: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9118"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fiteamos el CountVectorizer al set de training especificando una min_df=5 y \n",
    "# extrayendo 1-gramas and 2-gramas. Cuenta frecuencia por gramas\n",
    "# 2 gramas= 2 palabras por columna\n",
    "\n",
    "vect = CountVectorizer(min_df=5, ngram_range=(1,3)).fit(X_train)\n",
    "\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.9186201178116741\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver = 'liblinear')\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefs menores:\n",
      "['mala' 'mal' 'malo' 'peor' 'horrible' 'deja' 'excelente ambiente'\n",
      " 'malisima' 'caro' 'desastre']\n",
      "\n",
      "Coefs mayores: \n",
      "['excelente' 'espectacular' 'muy buena' 'rico' 'excelentes' 'exelente'\n",
      " 'muy bueno' 'super' 'buen' 'increíble']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "print('Coefs menores:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Coefs mayores: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
