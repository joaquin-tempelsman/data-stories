{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import math\n",
    "import operator\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.tools as tls\n",
    "import plotly.graph_objs as go\n",
    "from plotly.graph_objs import *\n",
    "from plotly.offline import init_notebook_mode, iplot, plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = 10, 10\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV, Ridge, RidgeCV\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feather\n",
    "df = feather.read_dataframe(\"E:/Users/Johana/Documents/DH/Trabajo Final/principal.feather\")\n",
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_principales = ['price_aprox_usd','property_type','surface_covered_in_m2','provincia']\n",
    "df_reg = df[columnas_principales]\n",
    "df_modelo= df_reg.dropna(axis =0 , how = 'any', subset = columnas_principales)\n",
    "df_modelo.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviso distribución de variable dependiente\n",
    "\n",
    "sns.distplot(df_modelo['price_aprox_usd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies = pd.get_dummies(df_modelo, columns = [ 'provincia', 'property_type'], drop_first = True)\n",
    "df_dummies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(df_dummies.price_aprox_usd)\n",
    "\n",
    "x= df_dummies.drop(columns=['price_aprox_usd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviso la varianza para ver si es necesario normalizar\n",
    "print([x[col].var() for col in x.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizacion por std\n",
    "from sklearn import datasets, preprocessing\n",
    "stdscaler = preprocessing.StandardScaler()\n",
    "xs2 = stdscaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convierto en Dataframe\n",
    "X = pd.DataFrame(xs2, columns=x.columns)\n",
    "X.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviso varianza despues de normalizar y veo que todas las variables quedaron con varianza 1\n",
    "print([X[col].var() for col in X.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estudiamos VIF para cuantificar la intensidad de la multicolinealidad\n",
    "#Si VIF>10, la multicolinealidad es alta\n",
    "\n",
    "import statsmodels.stats.outliers_influence as oi\n",
    "\n",
    "for i in range(len(X.columns)):\n",
    "    vif_col = oi.variance_inflation_factor(np.matrix(X), i)\n",
    "    print('columna ' + str(i) + \" \" + str(vif_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "#agrego el intercepto\n",
    "X_intercept = sm.add_constant(X)\n",
    "\n",
    "y.index = range(y.shape[0])\n",
    "\n",
    "# Fit and summarize OLS model (OLS = ordinary least square linear regression) Veo las descritivas del modelo\n",
    "model_intercept = sm.OLS(y, X_intercept)\n",
    "model_intercept = model_intercept.fit()\n",
    "print (model_intercept.summary())\n",
    "predictions_intercept = model_intercept.predict(X_intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculo de residuos\n",
    "\n",
    "predictions_intercept_df = pd.DataFrame(predictions_intercept, columns=['price_aprox_usd'])\n",
    "residuos_intercept = y - predictions_intercept_df\n",
    "print(residuos_intercept.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verifico la distribución y que la media de los residuos sea cero\n",
    "sns.distplot(residuos_intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verifico homocedasticidad con base en p_value\n",
    "#supuesto: Para cualquier valor de la variable explicativa, el error tienen la misma varianza\n",
    "import statsmodels.stats.api as sms\n",
    "\n",
    "resids_standardized = model_intercept.get_influence().resid_studentized_internal\n",
    "\n",
    "resids = model_intercept.resid\n",
    "\n",
    "bp_test = pd.DataFrame(sms.het_breuschpagan(resids, model_intercept.model.exog), \n",
    "                       columns=['value'],\n",
    "                       index=['Lagrange multiplier statistic', 'p-value', 'f-value', 'f p-value'])\n",
    "\n",
    "\n",
    "gq_test = pd.DataFrame(sms.het_goldfeldquandt(resids, model_intercept.model.exog)[:-1],\n",
    "                       columns=['value'],\n",
    "                       index=['F statistic', 'p-value'])\n",
    "\n",
    "print('\\n Breusch-Pagan test ----')\n",
    "print(bp_test)\n",
    "print('\\n Goldfeld-Quandt test ----')\n",
    "print(gq_test)\n",
    "#Si todo es consistente los dos test deberian dar el mismo resultado (significativo o no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos los gráficos de los residuos, no obtengo una linea horizontal (supuesto de homocedasticidad)\n",
    "fig, ax = plt.subplots(1,2)\n",
    "\n",
    "fitted_vals = predictions_intercept\n",
    "\n",
    "sns.regplot(x=fitted_vals, y=resids, lowess=True, ax=ax[0], line_kws={'color': 'red'})\n",
    "ax[0].set_title('Residuals vs Fitted', fontsize=16)\n",
    "ax[0].set(xlabel='Fitted Values', ylabel='Residuals')\n",
    "\n",
    "sns.regplot(x=fitted_vals, y=np.sqrt(np.abs(resids_standardized)), lowess=True, ax=ax[1], line_kws={'color': 'red'})\n",
    "ax[1].set_title('Scale-Location', fontsize=16)\n",
    "ax[1].set(xlabel='Fitted Values', ylabel='sqrt(abs(Residuals))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifico si los residuos tienen distribucion normal. (con un grafico de datos reales vs simulados). Deberia dar una recta.\n",
    "#el grafico es en quantiles\n",
    "\n",
    "sm.ProbPlot(model_intercept.resid).qqplot(line='s');\n",
    "plt.title('Q-Q plot');\n",
    "\n",
    "jb = stats.jarque_bera(model_intercept.resid)\n",
    "sw = stats.shapiro(model_intercept.resid)\n",
    "ad = stats.anderson(model_intercept.resid, dist='norm')\n",
    "ks = stats.kstest(model_intercept.resid, 'norm')\n",
    "\n",
    "print(f'Jarque-Bera test ---- statistic: {jb[0]:.4f}, p-value: {jb[1]}')\n",
    "print(f'Shapiro-Wilk test ---- statistic: {sw[0]:.4f}, p-value: {sw[1]:.4f}')\n",
    "print(f'Kolmogorov-Smirnov test ---- statistic: {ks.statistic:.4f}, p-value: {ks.pvalue:.4f}')\n",
    "print(f'Anderson-Darling test ---- statistic: {ad.statistic:.4f}, 5% critical value: {ad.critical_values[2]:.4f}')\n",
    "print('If the returned AD statistic is larger than the critical value, then for the 5% significance level, the null hypothesis that the data come from the Normal distribution should be rejected.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verifico el R2 y el error de la regresion\n",
    "print('r2: ' + str(model_intercept.rsquared))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divido los datos en train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=53)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el RMSE\n",
    "\n",
    "lm = LinearRegression(fit_intercept=True)\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "y = y_train\n",
    "y_pred = lm.predict(X_train)\n",
    "\n",
    "\n",
    "\n",
    "#definimos la raiz del error cuadratico medio\n",
    "rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "print(\" Score Test Lineal: %.2f\\n\" % lm.score(X_train, y_train))\n",
    "print(\" Train RMSE lineal   : %.2f \\n\" % rmse(y_train,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#los alfas se crean para hacer un tunning de los hiperparámetros de los modelos en base a validación cruzada\n",
    "#despues creo la regresion y le paso el alfa que obtuve\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "alfas_ridge = np.linspace(0.001, 0.3, 300)\n",
    "lm_ridge_cv= RidgeCV(alphas=alfas_ridge, cv=kf, normalize=False, fit_intercept = True)\n",
    "lm_ridge_cv.fit(X_train, y_train)\n",
    "print('Alpha Ridge:', lm_ridge_cv.alpha_)   \n",
    "\n",
    "#utilizo el alfa del paso anterior y  fiteo con un intercepto\n",
    "\n",
    "model_ridge = Ridge(lm_ridge_cv.alpha_, normalize=False, fit_intercept = True)\n",
    "model_ridge.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred_ridge = model_ridge.predict(X_train)\n",
    "np.sqrt(mean_squared_error(y_train, y_pred_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pruebo lo mismo que en el paso anterior pero con lasso para verificar consistencia y encontrar el mejor modelo\n",
    "alfas_lasso = np.linspace(0.1, 0.5, 300)\n",
    "lm_lasso_cv = LassoCV(alphas=alfas_lasso, cv=kf, normalize=False, fit_intercept = True)\n",
    "lm_lasso_cv.fit(X_train, y_train)\n",
    "print('Alpha LASSO:', lm_lasso_cv.alpha_)\n",
    "\n",
    "\n",
    "model_lasso = Lasso(lm_lasso_cv.alpha_, normalize=False, fit_intercept = True)\n",
    "model_lasso.fit(X_train, y_train)\n",
    "y_pred_lasso = model_lasso.predict(X_train)\n",
    "np.sqrt(mean_squared_error(y_train, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el R2 para ridge y Lasso\n",
    "\n",
    "print(\"Score Train Ridge : %.2f\\n\" % lm_ridge_cv.score(X_train, y_train),\n",
    "      \"Score Train Lasso : %.2f\\n\" %  lm_lasso_cv.score(X_train, y_train))\n",
    "\n",
    "# Calculamos el RMSE\n",
    "rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "\n",
    "print(\" Train RMSE lineal   : %.2f \\n\" % rmse(y_train,y_pred_lm),\n",
    "      \"Train RMSE Ridge    : %.2f \\n\" % rmse(y_train,y_pred_ridge),\n",
    "      \"Train RMSE Lasso    : %.2f \\n\" % rmse(y_train,y_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacemos el calculo con los datos de test (score y error cuadratico medio)\n",
    "\n",
    "lm.fit(X_test, y_test)\n",
    "\n",
    "y_pred_lmtest = lm.predict(X_test)\n",
    "print(\" Score Test Lineal: %.2f\\n\" % lm.score(X_test, y_test))\n",
    "print(\" Test RMSE lineal= %.2f\\n\" % rmse(y_test, y_pred_lmtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pruebo con test ridge\n",
    "lm_ridge_cv.fit(X_test, y_test)\n",
    "print('Alpha Ridge:', lm_ridge_cv.alpha_) \n",
    "\n",
    "y_pred_ridgetest = model_ridge.predict(X_test)\n",
    "\n",
    "np.sqrt(mean_squared_error(y_test, y_pred_ridgetest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pruebo con test lasso\n",
    "model_lasso.fit(X_test, y_test)\n",
    "y_pred_lassotest = model_lasso.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred_lassotest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valores para test\n",
    "\n",
    "\n",
    "print(\"Score Test Ridge : %.2f\\n\" % lm_ridge_cv.score(X_test, y_test),\n",
    "      \"Score Test Lasso : %.2f\\n\" %  lm_lasso_cv.score(X_test, y_test))\n",
    "\n",
    "\n",
    "print(\"Test RMSE Ridge = %.2f\\n\" %  rmse(y_test, y_pred_ridgetest),\n",
    "      \"Test RMSE Lasso = %.2f\" %  rmse(y_test, y_pred_lassotest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deben compararse el score, el r2 y el rsme de los tres modelos para sacar alguna conclusión y ponerla en la ppt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
