{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from requests_testadapter import Resp\n",
    "import requests\n",
    "#from requests_file import FileAdapter\n",
    "import os.path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = pd.read_csv('reviews_sep2_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valores unicos en COMIDA ['Excelente' 'Muy bueno' 'Bueno' 'Regular']\n",
      "valores unicos en SERVICIO ['Excelente' 'Regular' 'Muy bueno' 'Bueno']\n",
      "valores unicos en AMBIENTE ['Excelente' 'Muy bueno' 'Regular' 'Bueno']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resto</th>\n",
       "      <th>fecha</th>\n",
       "      <th>review</th>\n",
       "      <th>comida</th>\n",
       "      <th>servicio</th>\n",
       "      <th>ambiente</th>\n",
       "      <th>tokened</th>\n",
       "      <th>normal</th>\n",
       "      <th>nonstop</th>\n",
       "      <th>nopoint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-amigos-del-mar-608</td>\n",
       "      <td>12/07/2015</td>\n",
       "      <td>el mejor lugar de la Argentina para comer comi...</td>\n",
       "      <td>Excelente</td>\n",
       "      <td>Excelente</td>\n",
       "      <td>Excelente</td>\n",
       "      <td>['el', 'mejor', 'lugar', 'de', 'la', 'Argentin...</td>\n",
       "      <td>['el', 'mejor', 'lugar', 'de', 'la', 'argentin...</td>\n",
       "      <td>['mejor', 'lugar', 'argentina', 'comer', 'comi...</td>\n",
       "      <td>['mejor', 'lugar', 'argentina', 'comer', 'comi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-amigos-del-mar-608</td>\n",
       "      <td>22/06/2015</td>\n",
       "      <td>El Curry Udon excelente, hacía mucho que no co...</td>\n",
       "      <td>Muy bueno</td>\n",
       "      <td>Excelente</td>\n",
       "      <td>Excelente</td>\n",
       "      <td>['El', 'Curry', 'Udon', 'excelente', ',', 'hac...</td>\n",
       "      <td>['el', 'curry', 'udon', 'excelente', ',', 'hac...</td>\n",
       "      <td>['curry', 'udon', 'excelente', ',', 'hacía', '...</td>\n",
       "      <td>['curry', 'udon', 'excelente', 'hacía', 'comía...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-amigos-del-mar-608</td>\n",
       "      <td>06/01/2015</td>\n",
       "      <td>La relación calidad-precio fue mala (muy caro ...</td>\n",
       "      <td>Muy bueno</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Muy bueno</td>\n",
       "      <td>['La', 'relación', 'calidad-precio', 'fue', 'm...</td>\n",
       "      <td>['la', 'relación', 'calidad-precio', 'fue', 'm...</td>\n",
       "      <td>['relación', 'calidad-precio', 'mala', '(', 'c...</td>\n",
       "      <td>['relación', 'calidad-precio', 'mala', 'caro',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 resto       fecha  \\\n",
       "0  -amigos-del-mar-608  12/07/2015   \n",
       "1  -amigos-del-mar-608  22/06/2015   \n",
       "2  -amigos-del-mar-608  06/01/2015   \n",
       "\n",
       "                                              review     comida   servicio  \\\n",
       "0  el mejor lugar de la Argentina para comer comi...  Excelente  Excelente   \n",
       "1  El Curry Udon excelente, hacía mucho que no co...  Muy bueno  Excelente   \n",
       "2  La relación calidad-precio fue mala (muy caro ...  Muy bueno    Regular   \n",
       "\n",
       "    ambiente                                            tokened  \\\n",
       "0  Excelente  ['el', 'mejor', 'lugar', 'de', 'la', 'Argentin...   \n",
       "1  Excelente  ['El', 'Curry', 'Udon', 'excelente', ',', 'hac...   \n",
       "2  Muy bueno  ['La', 'relación', 'calidad-precio', 'fue', 'm...   \n",
       "\n",
       "                                              normal  \\\n",
       "0  ['el', 'mejor', 'lugar', 'de', 'la', 'argentin...   \n",
       "1  ['el', 'curry', 'udon', 'excelente', ',', 'hac...   \n",
       "2  ['la', 'relación', 'calidad-precio', 'fue', 'm...   \n",
       "\n",
       "                                             nonstop  \\\n",
       "0  ['mejor', 'lugar', 'argentina', 'comer', 'comi...   \n",
       "1  ['curry', 'udon', 'excelente', ',', 'hacía', '...   \n",
       "2  ['relación', 'calidad-precio', 'mala', '(', 'c...   \n",
       "\n",
       "                                             nopoint  \n",
       "0  ['mejor', 'lugar', 'argentina', 'comer', 'comi...  \n",
       "1  ['curry', 'udon', 'excelente', 'hacía', 'comía...  \n",
       "2  ['relación', 'calidad-precio', 'mala', 'caro',...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('valores unicos en COMIDA',df_reviews.comida.unique())\n",
    "print ('valores unicos en SERVICIO',df_reviews.servicio.unique())\n",
    "print ('valores unicos en AMBIENTE',df_reviews.ambiente.unique())\n",
    "df_reviews.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valores unicos en COMIDA [4 3 2 1]\n",
      "valores unicos en SERVICIO [4 1 3 2]\n",
      "valores unicos en AMBIENTE [4 3 1 2]\n"
     ]
    }
   ],
   "source": [
    "def valoracion_a_numeros(valor):\n",
    "    if valor == 'Excelente':\n",
    "        return 4\n",
    "    if valor == 'Muy bueno':\n",
    "        return 3\n",
    "    if valor == 'Bueno':\n",
    "        return 2\n",
    "    if valor == 'Regular':\n",
    "        return 1\n",
    "\n",
    "columnas_valoracion = ['comida','servicio','ambiente']\n",
    "for item in columnas_valoracion:\n",
    "    df_reviews[item] = df_reviews[item].apply(valoracion_a_numeros)\n",
    "\n",
    "print ('valores unicos en COMIDA',df_reviews.comida.unique())\n",
    "print ('valores unicos en SERVICIO',df_reviews.servicio.unique())\n",
    "print ('valores unicos en AMBIENTE',df_reviews.ambiente.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviews originales 28286\n",
      "reviews segmentadas negativas 7419\n",
      "reviews segmentadas positivas 10802\n"
     ]
    }
   ],
   "source": [
    "mask_negative = (df_reviews[\"comida\"] < 3) & (df_reviews[\"servicio\"] < 3) & (df_reviews[\"ambiente\"] < 3)\n",
    "mask_positive = (df_reviews[\"comida\"] > 2) & (df_reviews[\"servicio\"] > 2 ) & (df_reviews[\"ambiente\"] >2 )\n",
    "# mask_com = df_reviews['comida'] = 1\n",
    "# mask_serv = df_reviews['servicio'] = 1\n",
    "# mask_amb = df_reviews['ambiente'] = 1\n",
    "# df_reviews_neg = df_reviews[mask_com] & df_reviews[mask_serv] & df_reviews[mask_amb]\n",
    "\n",
    "print ('reviews originales',df_reviews.fecha.count())\n",
    "\n",
    "df_negative = df_reviews[mask_negative]\n",
    "print ('reviews segmentadas negativas',df_negative.fecha.count())\n",
    "\n",
    "df_positive = df_reviews[mask_positive]\n",
    "print ('reviews segmentadas positivas',df_positive.fecha.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 10802, n_features: 8936 POSITIVO\n",
      "n_samples: 7419, n_features: 9215 NEGATIVO\n"
     ]
    }
   ],
   "source": [
    "corpus_positivo = df_positive.nopoint\n",
    "corpus_negativo = df_negative.nopoint\n",
    "\n",
    "\n",
    "# Vectorizamos el texto con TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, max_features=100000,\n",
    "                             min_df=2, use_idf=True) #le saque el stopwords, porque ya lo hicimos antes\n",
    "\n",
    "X_positivo = vectorizer.fit_transform(corpus_positivo)\n",
    "X_negativo = vectorizer.fit_transform(corpus_negativo)\n",
    "\n",
    "print(\"n_samples: %d, n_features: %d POSITIVO\" % X_positivo.shape)\n",
    "print(\"n_samples: %d, n_features: %d NEGATIVO\" % X_negativo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_positivo = nltk.FreqDist(corpus_positivo)\n",
    "dist_negativo = nltk.FreqDist(corpus_negativo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'[]': 4, \"['hoy', '25', 'mayo', 'hecho', 'pedido', 'ayer', 'ser', 'entregado', 'hoy', '13', 'registrado', 'hora', 'dirección', 'teléfono', 'siendo', '14', 'dejado', 'clavado', 'entrega', 'nunca', 'llegó', 'nadie', 'responde', 'ninguno', 'teléfonos', 'seriedad', 'proceder', 'requiere', 'mayor', 'comentario']\": 3, \"['pagina', 'da', 'opción', 'encargar', 'pedido', 'dia', 'siguiente', 'fecha', 'determinada', 'realice', 'manera', 'pedido', 'jamas', 'llego', 'llame', 'restaurant', 'dijeron', 'trabajan', 'así', 'pedido', 'dia', 'pagina', 'especifica', 'pedidos', 'pueden', 'reservar', 'dias', 'antelación', 'sumado', 'atención', 'pésima', 'sumamente', 'irrespetuosos', 'vergüenza']\": 3, \"['precio', 'platos', 'vinsanto', 'excesivamente', 'oneroso', 'calidad', 'mismos', 'caso', 'pastas', 'salsa', 'económica', 'valor', '$', '68', 'parece', 'despropósito', 'si', 'luego', 'puede', 'descubrir', 'dónde', 'ubicada', 'salsa', 'plato', 'pastas', 'elegido', 'atención', 'pésima', 'mozos', 'saben', 'hacer', 'recomendaciones']\": 3, \"['desastre', 'tres', 'escalopes', 'duros', 'incomibles', 'sirve', 'q', 'reintegren', 'dinero', 'después', 'mozo', 'tal', 'mecho', 'tiempo', 'justificándose', 'mala', 'gana', 'mucha', 'gente', 'atender', '.los', 'ravioles', 'ricota', 'pasables', 'zafe', 'pedí', 'pollo', 'parrilla', 'ahí', 'pueden', 'equivocar', 'salir', 'das', 'cuenta', 'ruido', 'permanente', 'q', 'aliena', 'clientes', 'mozos', 'igual', 'recomiendo']\": 2, \"['debut', 'despedida', 'hoy', 'desayunar', 'pedi', 'desayuno', 'panadero', 'cafe', 'leche', 'tostadas', 'mermelada', 'queso', 'blanco', 'pregunte', 'mermelada', 'dijeron', 'frutilla', 'pedi', 'pan', 'bien', 'tostado', 'tardo', 'eternidad', 'pesima', 'atencion', 'modales', 'reclame', 'llegaba', 'desayuno', 'dijeron', 'habian', 'juntado', 'varios', 'desayunos', 'identicos', '¿', 'llego', 'cafe', 'frio', 'tostadas', 'mas', 'tostadas', 'pan', 'calentado', 'tostado', 'mermelada', 'tomate']\": 2, \"['recomendable', 'especial', 'parejas', 'unas', 'gambas', 'ajillo', 'entrada', 'anunciaban', 'calidad', 'segundo', 'plato', 'ciervo', 'malbec', 'increible', 'música', 'vino', 'excelentes', 'gran', 'atención', 'recomendable']\": 2, \"['antonella', 'gomez', 'desastre', 'primera', 'vez', 'compré', 'empanadas', 'mandaron', 'todas', 'reventadas', 'exagerando', 'si', 'saben', 'pasan', 'caja', 'reventadas', 'envían', 'avellano', 'sólo', 'difunta', 'situación', 'sino', 'invitados', 'porsupuesto', 'creo', 'clientes', 'después', 'ayer']\": 2, \"['cerrado']\": 2, \"['caro', 'calidad', 'comida', 'ofrecen']\": 2, ...})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_negativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({\"['excelente']\": 22, \"['recomendable']\": 6, \"['rico']\": 6, \"['excelente', 'lugar']\": 5, \"['bueno']\": 5, \"['ir', 'restaurant', 'comida', 'húngara', 'comer', 'suprema', 'vayas']\": 4, \"['bien']\": 4, \"['hola', 'anoche', 'amigos', 'ambiente', 'bueno', 'bien', 'decorado', 'acogedor', 'mesas', 'amplias', 'comida', 'cubrió', 'expectativas', 'excelente', 'presentación', 'platos', 'bien', 'atendido', 'camarera', 'margarita', 'sugerencia', 'detalle', 'considerar', 'falta', 'mantel', 'mesas', 'recomiendo', 'volveremos', '.-']\": 4, \"['comida', 'unidos', 'bueno', 'porciones', 'pequeno', 'salsas', 'bien', 'necisito', 'dos', 'sandwiches', 'pollo', 'frito', 'si', 'quires', 'satisfecho']\": 4, \"['riquisimo']\": 3, ...})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_positivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(100,random_state = 1) \n",
    "normalizer = Normalizer(copy=False)\n",
    "lsa = make_pipeline(svd, normalizer)\n",
    "X_positivo = lsa.fit_transform(X_positivo)\n",
    "X_negativo = lsa.fit_transform(X_negativo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking de términos por tópico - reviews positivos:\n",
      " bien mas pedimos si dos plato platos servicio comer pizza carne nunca papas mesa lugar\n",
      " mala comida atención atencion lugar mas caro mal recomiendo pedimos nunca vuelvo calidad pizza dos\n",
      " buena lugar comida bien pizza atención precios precio comer calidad ambiente rica atencion ir si\n"
     ]
    }
   ],
   "source": [
    "#tratamiento DF positivo\n",
    "k_value = 3\n",
    "from sklearn.cluster import KMeans\n",
    "km = KMeans(n_clusters=k_value, max_iter=100, n_init=10, random_state = 10)\n",
    "km.fit(X_positivo)\n",
    "\n",
    "# Hacemos la transformación inversa para ver el peso de los features originales (10000 dim)\n",
    "original_space_centroids = svd.inverse_transform(km.cluster_centers_)\n",
    "\n",
    "# La función argsort nos da los índices ordenados\n",
    "order_centroids = original_space_centroids.argsort()[:, ::-1]\n",
    "\n",
    "# Imprimimos los términos más \"pesados\" (frecuentes) para cada categoría\n",
    "# Con los índices ordenados, llamamos a la descripción de las palabras que construyó el Vectorizer()\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "print(\"Ranking de términos por tópico - reviews positivos:\")\n",
    "\n",
    "for i in range(k_value):\n",
    "    print(end='')\n",
    "    for ind in order_centroids[i, :15]:\n",
    "       \n",
    "        print(' %s' % terms[ind], end='')\n",
    "    print()\n",
    "\n",
    "# Nos quedamos con los índices ordenados más importantes en cada tópico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking de términos por tópico - reviews negativos:\n",
      " lugar bien buena pizza calidad atención comer precio si precios platos caro ambiente ir bueno\n",
      " pedimos mas dos mesa nunca plato mal papas trajeron si mozo vino solo minutos desastre\n",
      " comida mala lugar atención buena precios servicio ambiente calidad atencion bien si caro mal mas\n"
     ]
    }
   ],
   "source": [
    "#tratamiento DF negativo\n",
    "k_value = 3\n",
    "from sklearn.cluster import KMeans\n",
    "km = KMeans(n_clusters=k_value, max_iter=100, n_init=10, random_state= 3)\n",
    "km.fit(X_negativo)\n",
    "\n",
    "# Hacemos la transformación inversa para ver el peso de los features originales (10000 dim)\n",
    "original_space_centroids = svd.inverse_transform(km.cluster_centers_)\n",
    "\n",
    "# La función argsort nos da los índices ordenados\n",
    "order_centroids = original_space_centroids.argsort()[:, ::-1]\n",
    "\n",
    "# Imprimimos los términos más \"pesados\" (frecuentes) para cada categoría\n",
    "# Con los índices ordenados, llamamos a la descripción de las palabras que construyó el Vectorizer()\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "print(\"Ranking de términos por tópico - reviews negativos:\")\n",
    "\n",
    "for i in range(k_value):\n",
    "    print(end='')\n",
    "    for ind in order_centroids[i, :15]:\n",
    "        print(' %s' % terms[ind], end='')\n",
    "    print()\n",
    "\n",
    "# Nos quedamos con los índices ordenados más importantes en cada tópico"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
